{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Codigo simplificado.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOIOWiZjjz7efm+4gvb8AKR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuilhermeMCP/Stock-Prediction/blob/main/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9t0oMjvXyJu"
      },
      "source": [
        "#Importando pacotes necessários\r\n",
        "import pandas as pd\r\n",
        "import matplotlib as mpl\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "import warnings\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "from keras.regularizers import L1L2\r\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, LSTM, Dropout, LeakyReLU\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\r\n",
        "\r\n",
        "from sklearn.metrics import r2_score, mean_squared_error\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\r\n",
        "\r\n",
        "mpl.rcParams['figure.figsize'] = (20, 8)\r\n",
        "mpl.rcParams['axes.grid'] = False"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQsVCFVHX4Q6"
      },
      "source": [
        "#--------------------VARIÁVEIS--------------------------\r\n",
        "\r\n",
        "cols = ['Data', 'LNCfech', 'LNCab', 'CFech', 'Cab', 'Ibov']\r\n",
        "\r\n",
        "df = pd.read_csv('TesteBBDC.csv', thousands=',')\r\n",
        "df = df[2000:]\r\n",
        "df.dropna(inplace=True)\r\n",
        "df = df.drop(df[(df.LNCfech == '-') | (df.Ibov == '-')].index)\r\n",
        "df = df.reset_index()\r\n",
        "#\r\n",
        "df = df[cols].astype(str)\r\n",
        "for i in cols:\r\n",
        "    for j in range(0, len(df)):\r\n",
        "        df[i][j] = df[i][j].replace(',', '')\r\n",
        "\r\n",
        "for col in df.columns:\r\n",
        "  if (col != \"Data\") & (col != \"date\"):\r\n",
        "    df = df.astype({col:\"float32\"})\r\n",
        "\r\n",
        "\r\n",
        "# -----------------ANÁLISE DE CORRELAÇÃO----------------------------\r\n",
        "#shift é correlação do preço com x dias atras\r\n",
        "# shift = 0\r\n",
        "# correlations = correlation_calc(cols[2], cols[1:], df, shift)\r\n",
        "# correlations\r\n",
        "#--------------------------------------------------------------------\r\n",
        "\r\n",
        "#fazendo retabilidade ibovespa\r\n",
        "change = []\r\n",
        "change.append(\"-\")\r\n",
        "for i in range(0,len(df['Ibov'])-1):\r\n",
        "  change.append(df['Ibov'].iloc[i+1] - df['Ibov'].iloc[i])\r\n",
        "df['IbovChange'] = change\r\n",
        "\r\n",
        "#fazendo mm10rent\r\n",
        "change = []\r\n",
        "for i in range(0,10):\r\n",
        "  change.append(\"-\")\r\n",
        "for i in range(0,len(df['CFech'])-10):\r\n",
        "  soma = 0\r\n",
        "  for j in range(1,11):\r\n",
        "    rent = df['CFech'].iloc[i+j] - df['CFech'].iloc[i]\r\n",
        "    soma = soma + rent\r\n",
        "  change.append(soma/10)\r\n",
        "df['MM10'] = change\r\n",
        "\r\n",
        "\r\n",
        "df = df.drop(df[(df.MM10 == '-') | (df.IbovChange == '-')].index)\r\n",
        "df = df.reset_index()\r\n",
        "\r\n",
        "cols2 = ['LNCfech', 'LNCab', 'MM10', 'IbovChange']\r\n",
        "\r\n",
        "targetColumn = 'LNCab'\r\n",
        "predTargetColumn = targetColumn + '_Pred'\r\n",
        "targetColumnIndex = 1\r\n",
        "\r\n",
        "df_input = df[cols2]\r\n",
        "scaler = MinMaxScaler()\r\n",
        "data_scaled = scaler.fit_transform(df_input)\r\n",
        "features = data_scaled\r\n",
        "target = data_scaled[:,targetColumnIndex]\r\n",
        "\r\n",
        "\r\n",
        "horizonte_de_predicao = [0,1,2,3,4]\r\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SunZE1a9YOS_"
      },
      "source": [
        "warnings.filterwarnings('ignore')\r\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\r\n",
        "\r\n",
        "\r\n",
        "for j in range(0, len(horizonte_de_predicao)):\r\n",
        "\r\n",
        "  x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.30, random_state=123, shuffle = False)\r\n",
        "  \r\n",
        "  #Faz um shift nos dados de acordo com o horizonte de predição\r\n",
        "  if (horizonte_de_predicao[j] > 0):\r\n",
        "    y_train = y_train[horizonte_de_predicao[j]:]\r\n",
        "    x_train = x_train[:-horizonte_de_predicao[j]]\r\n",
        "    y_test = y_test[horizonte_de_predicao[j]:]\r\n",
        "    x_test = x_test[:-horizonte_de_predicao[j]]\r\n",
        "\r\n",
        "  #esse loop existe para repetir o mesmo teste mais de uma vez\r\n",
        "  for f in range(0, 5):\r\n",
        "\r\n",
        "    win_length = 1\r\n",
        "    batch_size = 256\r\n",
        "    epochs = 100\r\n",
        "    num_features = len(df_input.columns)\r\n",
        "    train_generator = TimeseriesGenerator(x_train, y_train, length=win_length, sampling_rate=1, batch_size=batch_size)\r\n",
        "    test_generator = TimeseriesGenerator(x_test, y_test, length=win_length, sampling_rate=1, batch_size=batch_size)\r\n",
        "\r\n",
        "\r\n",
        "    model = build_neural_network( win_length=win_length, epochs=epochs, batch_size=batch_size,\r\n",
        "                                num_features=num_features, data=train_generator, evaluate_data=test_generator,\r\n",
        "                                  learning_rate=0.1)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    #-------------------------------------- PREDICTIONS -----------------------------------------------------\r\n",
        "    #predictions\r\n",
        "    predictions_TEST=model.predict_generator(test_generator)\r\n",
        "    predictions_TEST=predictions_TEST[:,0]\r\n",
        "    df_pred=pd.concat([pd.DataFrame(predictions_TEST), pd.DataFrame(x_test[:,1:][win_length:])], axis=1)\r\n",
        "    rev_trans_TEST=scaler.inverse_transform(df_pred)\r\n",
        "    df_final_TEST=df_input[predictions_TEST.shape[0]*-1:]\r\n",
        "    df_final_TEST[predTargetColumn]=rev_trans_TEST[:,0]\r\n",
        "\r\n",
        "    #avaliando resultado\r\n",
        "    pocid_TEST = pocid_calculate(df_final_TEST[targetColumn], df_final_TEST[predTargetColumn], 1)\r\n",
        "    pocid_ingenuo = pocid_calculate(df_final_TEST[targetColumn][1:], df_final_TEST[targetColumn][:-1], 1)\r\n",
        "    theil_TEST = theil_calculate(df_final_TEST[targetColumn], df_final_TEST[predTargetColumn], 1)\r\n",
        "    emq_TEST = emq_calculate(df_final_TEST[targetColumn], df_final_TEST[predTargetColumn])\r\n",
        "    r2_TEST = r2_calculate(df_final_TEST[targetColumn], df_final_TEST[predTargetColumn])\r\n",
        "    \r\n",
        "    print(\"d+ (days future)\",horizonte_de_predicao[j]+1)\r\n",
        "    print(\"POCID ingenuo (%, bom alto) = \",pocid_ingenuo)\r\n",
        "    print(\"POCID TEST (%, bom alto) = \",pocid_TEST)\r\n",
        "    print(\"THEIL TEST (bom < 1) = \",theil_TEST)\r\n",
        "    print(\"R2 TEST (bom prox 1) = \",r2_TEST)\r\n",
        "    print(\"EMQ TEST (quanto menor melhor) = \",emq_TEST)\r\n",
        "    print(\"--------------------------------------------------\")\r\n",
        "  \r\n",
        "  print(\"\\n\\n\")\r\n",
        "  print(\"---------------------------------------------------------------------\")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gktYy5P3Yl9H"
      },
      "source": [
        "\r\n",
        "def emq_calculate(real, pred):\r\n",
        "  soma = 0\r\n",
        "  for i in range(0, len(pred)):\r\n",
        "    soma = soma + (real.iloc[i] - pred.iloc[i])**2\r\n",
        "  return (soma/len(pred))\r\n",
        "\r\n",
        "\r\n",
        "def r2_calculate(real, pred):\r\n",
        "    r2 = r2_score( real, pred )\r\n",
        "    return r2\r\n",
        "\r\n",
        "\r\n",
        "def pocid_calculate(Cfech, Cfech_pred, horizonte_de_predicao):\r\n",
        "  mi = 0\r\n",
        "  soma = 0\r\n",
        "  for i in range(1, (len(Cfech))):\r\n",
        "    mi = (Cfech.iloc[i]-Cfech.iloc[i-horizonte_de_predicao])*(Cfech_pred.iloc[i]-Cfech_pred.iloc[i-horizonte_de_predicao])\r\n",
        "    if (mi > 0) :\r\n",
        "      soma = soma + 1\r\n",
        "  return (soma*100)/(len(Cfech)-horizonte_de_predicao-1)\r\n",
        "\r\n",
        "\r\n",
        "def theil_calculate(Cfech, Cfech_pred, horizonte_de_predicao):\r\n",
        "  soma1 = 0\r\n",
        "  soma2 = 0\r\n",
        "  for i in range(1, len(Cfech)):\r\n",
        "    soma1 = soma1 + (Cfech.iloc[i] - Cfech_pred.iloc[i])**2\r\n",
        "    soma2 = soma2 + (Cfech.iloc[i] - Cfech.iloc[i - horizonte_de_predicao])**2\r\n",
        "  return math.sqrt(soma1)/math.sqrt(soma2)\r\n",
        "\r\n",
        "def correlation_calc(principal, lista, dataFrame, shift = 0):\r\n",
        "  correlations = []\r\n",
        "  df_shifted = df.drop(df.index[:shift])\r\n",
        "  df_shifted = df_shifted.reset_index(drop=True)\r\n",
        "  for i in range(0, len(lista)):\r\n",
        "    correlations.append(lista[i] + \" = \" + str(df_shifted[principal].corr(dataFrame[lista[i]])))\r\n",
        "  return correlations\r\n",
        "\r\n",
        "\r\n",
        "def build_neural_network(win_length, epochs, batch_size, num_features, data, evaluate_data, learning_rate):\r\n",
        "\r\n",
        "  model = tf.keras.Sequential()\r\n",
        "  model.add(Dense(6, input_dim=num_features, activation='sigmoid'))\r\n",
        "  model.add(Dense(3,  activation='tanh'))\r\n",
        "  model.add(Dense(3,  activation='linear'))\r\n",
        "  model.add(Dense(1))\r\n",
        "\r\n",
        "  model.compile(optimizer = Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=[tf.metrics.MeanAbsoluteError()])   \r\n",
        "  early_stopping = EarlyStopping(monitor='var_loss', patience=2, mode='min')\r\n",
        "  history = model.fit(data, epochs=epochs, batch_size=batch_size, validation_data=evaluate_data, shuffle=False, callbacks=[early_stopping], verbose=0)\r\n",
        "  model.evaluate_generator(evaluate_data, verbose=0)\r\n",
        "\r\n",
        "  return model\r\n"
      ],
      "execution_count": 77,
      "outputs": []
    }
  ]
}